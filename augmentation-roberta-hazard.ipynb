{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# Replace 'your_file.csv' with the path to your CSV file\ndf = pd.read_csv('path_of_dataset')\nrow_count = len(df)\nprint(f\"Number of rows: {row_count}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\nfrom sklearn.metrics import accuracy_score, f1_score\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\nimport numpy as np\n\n\n\n# Load train and validation datasets\ntrain_data = pd.read_csv(\"incidents_train.csv\") # Replace with train or augment data CSV filename\nvalid_data = pd.read_csv(\"incidents_valid.csv\", index_col=0)\nprint(len(train_data['text']))\n\n# Combine title and text as input\ntrain_data['input_text'] =  train_data['text']\nvalid_data['input_text'] = valid_data['title'] + \" \" + valid_data['text']\n\n# Prepare labels\nlabel_mapping = {label: idx for idx, label in enumerate(train_data['hazard-category'].unique())}\nlabel_inverse_mapping = {idx: label for label, idx in label_mapping.items()}\ntrain_data['hazard-category'] = train_data['hazard-category'].map(label_mapping)\nvalid_data['hazard-category'] = valid_data['hazard-category'].map(label_mapping)\n\n# Define custom dataset for Roberta\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=256):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        inputs = self.tokenizer(\n            text,\n            max_length=self.max_len,\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\"\n        )\n        return {\n            'input_ids': inputs['input_ids'].squeeze(0),\n            'attention_mask': inputs['attention_mask'].squeeze(0),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n\n# Tokenizer and model\ntokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\nmodel = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(label_mapping))\n\n# Prepare datasets and dataloaders\ntrain_dataset = TextDataset(train_data['input_text'].tolist(), train_data['hazard-category'].tolist(), tokenizer)\nvalid_dataset = TextDataset(valid_data['input_text'].tolist(), valid_data['hazard-category'].tolist(), tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=16)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\n# Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training loop with loss tracking\nepochs = 100\nepoch_losses = []\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    num_batches = 0\n    \n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n        num_batches += 1\n        \n        loss.backward()\n        optimizer.step()\n        \n        # Print batch loss every 10 batches\n        # if num_batches % 100 == 0:\n        #     print(f\"Epoch {epoch+1}, Batch {num_batches}, Loss: {loss.item():.4f}\")\n    \n    avg_epoch_loss = total_loss / num_batches\n    epoch_losses.append(avg_epoch_loss)\n    print(f\"Epoch {epoch+1} completed. Average loss: {avg_epoch_loss:.4f}\")\n\n# Evaluation with detailed metrics\nmodel.eval()\nall_preds = []\nall_labels = []\nvalid_data['predicted-category'] = None\n\nwith torch.no_grad():\n    for i, batch in enumerate(valid_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(batch['label'].cpu().numpy())\n        \n        start_idx = i * valid_loader.batch_size\n        end_idx = start_idx + len(preds)\n        valid_data.iloc[start_idx:end_idx, valid_data.columns.get_loc('predicted-category')] = preds\n\n# Calculate metrics\naccuracy = accuracy_score(all_labels, all_preds)\nmacro_f1 = f1_score(all_labels, all_preds, average='macro')\nmacro_precision = precision_score(all_labels, all_preds, average='macro')\nmacro_recall = recall_score(all_labels, all_preds, average='macro')\ncm = confusion_matrix(all_labels, all_preds)\n\nprint(\"\\nMetrics:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Macro F1-Score: {macro_f1:.4f}\")\nprint(f\"Macro Precision: {macro_precision:.4f}\")\nprint(f\"Macro Recall: {macro_recall:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(cm)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader\n\n# Load your new data\ntest_data = pd.read_csv(\"unlabed_test.csv\")  # Replace with test data CSV filename\n\n# Combine title and text as input\ntest_data['input_text'] = test_data['title'] + \" \" + test_data['text']\n\n# Create test dataset\ntest_dataset = TextDataset(test_data['input_text'].tolist(), \n                          [0] * len(test_data),  # Dummy labels\n                          tokenizer)\ntest_loader = DataLoader(test_dataset, batch_size=16)\n\n# Make predictions\nmodel.eval()\nall_preds = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask)\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        all_preds.extend(preds)\n\n# Create results DataFrame\nresults_df = pd.DataFrame({\n    'index': range(len(all_preds)),\n    'hazard': [label_inverse_mapping[pred] for pred in all_preds]\n})\n\n# Save predictions\nresults_df.to_csv(\"FlanT5-RoBERTa-Hazard.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
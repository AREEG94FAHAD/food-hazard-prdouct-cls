{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T21:48:49.002635Z",
     "iopub.status.busy": "2025-01-27T21:48:49.002435Z",
     "iopub.status.idle": "2025-01-27T21:48:50.272055Z",
     "shell.execute_reply": "2025-01-27T21:48:50.270479Z",
     "shell.execute_reply.started": "2025-01-27T21:48:49.002616Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "df = pd.read_csv('augmentation-dataset-path')\n",
    "row_count = len(df)\n",
    "print(f\"Number of rows: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T08:24:14.823766Z",
     "iopub.status.busy": "2025-01-27T08:24:14.823477Z",
     "iopub.status.idle": "2025-01-27T08:26:17.269127Z",
     "shell.execute_reply": "2025-01-27T08:26:17.267916Z",
     "shell.execute_reply.started": "2025-01-27T08:24:14.823743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# working code \n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load train and validation datasets\n",
    "train_data = pd.read_csv(\"augmentation.csv\")\n",
    "train_data = train_data.sample(frac=1, random_state=2024)\n",
    "valid_data = pd.read_csv(\"/kaggle/input/food-datasets/incidents_valid.csv\", index_col=0)\n",
    "print(len(train_data['text']))\n",
    "\n",
    "# Combine title and text as input\n",
    "train_data['input_text'] =  train_data['text']\n",
    "valid_data['input_text'] = valid_data['title'] + \" \" + valid_data['text']\n",
    "\n",
    "# Prepare labels\n",
    "label_mapping = {label: idx for idx, label in enumerate(train_data['product-category'].unique())}\n",
    "label_inverse_mapping = {idx: label for label, idx in label_mapping.items()}\n",
    "train_data['product-category'] = train_data['product-category'].map(label_mapping)\n",
    "valid_data['product-category'] = valid_data['product-category'].map(label_mapping)\n",
    "\n",
    "# Define custom dataset for Roberta\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=len(label_mapping))\n",
    "\n",
    "# Prepare datasets and dataloaders\n",
    "train_dataset = TextDataset(train_data['input_text'].tolist(), train_data['product-category'].tolist(), tokenizer)\n",
    "valid_dataset = TextDataset(valid_data['input_text'].tolist(), valid_data['product-category'].tolist(), tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop with loss tracking\n",
    "epochs = 100\n",
    "epoch_losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print batch loss every 10 batches\n",
    "        # if num_batches % 100 == 0:\n",
    "        #     print(f\"Epoch {epoch+1}, Batch {num_batches}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_epoch_loss = total_loss / num_batches\n",
    "    epoch_losses.append(avg_epoch_loss)\n",
    "    print(f\"Epoch {epoch+1} completed. Average loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "# Evaluation with detailed metrics\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "valid_data['predicted-category'] = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(valid_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(batch['label'].cpu().numpy())\n",
    "        \n",
    "        start_idx = i * valid_loader.batch_size\n",
    "        end_idx = start_idx + len(preds)\n",
    "        valid_data.iloc[start_idx:end_idx, valid_data.columns.get_loc('predicted-category')] = preds\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "macro_precision = precision_score(all_labels, all_preds, average='macro')\n",
    "macro_recall = recall_score(all_labels, all_preds, average='macro')\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-26T15:35:30.445871Z",
     "iopub.status.busy": "2025-01-26T15:35:30.445498Z",
     "iopub.status.idle": "2025-01-26T15:35:41.451703Z",
     "shell.execute_reply": "2025-01-26T15:35:41.450911Z",
     "shell.execute_reply.started": "2025-01-26T15:35:30.445837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load your new data\n",
    "test_data = pd.read_csv(\"../unlabed_test.csv\")  # Replace with your CSV filename\n",
    "\n",
    "# Combine title and text as input\n",
    "test_data['input_text'] = test_data['title'] + \" \" + test_data['text']\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = TextDataset(test_data['input_text'].tolist(), \n",
    "                          [0] * len(test_data),  # Dummy labels\n",
    "                          tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'index': range(len(all_preds)),\n",
    "    'product': [label_inverse_mapping[pred] for pred in all_preds]\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "results_df.to_csv(\"augmentation-roberta-product.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6551605,
     "sourceId": 10596693,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
